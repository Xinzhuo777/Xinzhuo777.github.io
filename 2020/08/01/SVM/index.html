<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"xinzhuo777.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="SVM算法原理(一)间隔在给定训练集  D&#x3D;[(x_1,y_1）,(x_2，y_2),....,(x_m,y_m)] y_i&#x3D;+1or-1 函数间隔和几何间隔  我们定义一个超平面的表达式为  \pmb{y}&#x3D;w^T\pmb{x}+b则超平面上的一点x到该平面的距离(几何间隔)为：  \frac{|w^Tx+b|}{||w||}函数间隔考虑到y取值仅有1和-1，对于正样例则label为1，反之为-">
<meta property="og:type" content="article">
<meta property="og:title" content="[SVM]">
<meta property="og:url" content="http://xinzhuo777.github.io/2020/08/01/SVM/index.html">
<meta property="og:site_name" content="machine learning">
<meta property="og:description" content="SVM算法原理(一)间隔在给定训练集  D&#x3D;[(x_1,y_1）,(x_2，y_2),....,(x_m,y_m)] y_i&#x3D;+1or-1 函数间隔和几何间隔  我们定义一个超平面的表达式为  \pmb{y}&#x3D;w^T\pmb{x}+b则超平面上的一点x到该平面的距离(几何间隔)为：  \frac{|w^Tx+b|}{||w||}函数间隔考虑到y取值仅有1和-1，对于正样例则label为1，反之为-">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/Xinzhuo777/picgo/master/imagesvm%20.png">
<meta property="article:published_time" content="2020-08-01T05:15:38.000Z">
<meta property="article:modified_time" content="2020-09-10T11:08:30.000Z">
<meta property="article:author" content="Xinzhuo Li">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Xinzhuo777/picgo/master/imagesvm%20.png">

<link rel="canonical" href="http://xinzhuo777.github.io/2020/08/01/SVM/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>[SVM] | machine learning</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="machine learning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">machine learning</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://xinzhuo777.github.io/2020/08/01/SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Xinzhuo Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="machine learning">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [SVM]
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-01 13:15:38" itemprop="dateCreated datePublished" datetime="2020-08-01T13:15:38+08:00">2020-08-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-10 19:08:30" itemprop="dateModified" datetime="2020-09-10T19:08:30+08:00">2020-09-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="SVM算法原理-一"><a href="#SVM算法原理-一" class="headerlink" title="SVM算法原理(一)"></a>SVM算法原理(一)</h1><h6 id="间隔"><a href="#间隔" class="headerlink" title="间隔"></a>间隔</h6><p>在给定训练集</p>
<script type="math/tex; mode=display">
D=[(x_1,y_1）,(x_2，y_2),....,(x_m,y_m)]</script><script type="math/tex; mode=display">
y_i=+1or-1</script><ul>
<li>函数间隔和几何间隔</li>
</ul>
<p>我们定义一个超平面的表达式为</p>
<script type="math/tex; mode=display">
\pmb{y}=w^T\pmb{x}+b</script><p>则超平面上的一点x到该平面的距离(几何间隔)为：</p>
<script type="math/tex; mode=display">
\frac{|w^Tx+b|}{||w||}</script><p>函数间隔考虑到y取值仅有1和-1，对于正样例则label为1，反之为-1，即乘不改变其绝对值，故函数间隔的定义如下：</p>
<script type="math/tex; mode=display">
y_i(w^Tx+b)</script><p>来表示样本点到这个平面的函数间隔</p>
<ul>
<li><p>函数间隔和几何间隔的关系</p>
<p>如果找到了一个超平面可以正确分开这个数据集，那么意味着它的函数间隔大于和等于0，即对于一个正样例$y_i$=1,因为被正确分类了，所以$w^Tx+b&gt;0$,则有$y_i(w^T+b)&gt;0$(实际上有更严格限制的条件)，负样例同理。</p>
<p>由于$|y_i|=1$,所以函数间隔可以用几何间隔表示，即在样本集线性可分的情况下，对于一个成功分类的超平面而言，每个样本点到这个超平面的几何间隔就是函数间隔除以$w$范数</p>
</li>
<li><p>定义超平面到训练集的间隔</p>
</li>
</ul>
<p>我们定义超平面到训练集的间隔为这个超平面到训练集每个点的几何距离中的最小距离</p>
<p>$min\frac{y_i(w^Tx_i+b)}{||w||}$,表示为在每个几何间隔中找到最小的。因为$\frac{1}{||w||}$和具体的样本点无关，所以提出来原式化为$\frac{1}{||w||}min(y_i(w^Tx_i+b))$,表示为训练集每一个点到这个超平面的函数间隔中的最小值。</p>
<h5 id="SVM形式"><a href="#SVM形式" class="headerlink" title="SVM形式"></a>SVM形式</h5><p>基于以上的定义我们自然而然想到，我们要找到一个超平面，它不但可以正确分类，而且它到训练集的间隔是所有可以正确分类的超平面中最大的。即找到一组（w，b）使得$max(\frac{1}{||w||}min(y_i(w^Tx_i+b)))$</p>
<p><strong>我们需要注意到一个点</strong>：对于w和b同时进行缩放，即w-&gt;kw,b-&gt;kb,带入原式，值不变。</p>
<p>所以我们通过合理放缩使得$min(y_i(w^Tx_i+b))$=1(变相增加了约束)</p>
<p>对于不是离超平面最近的那些样本点，它们的$y_i(w^Tx_i+b)&gt;1$，所以化简完，即求解$max\frac{1}{||w||}$再次等价为$\frac{1}{2}min||w||^2$,$\frac{1}{2}$为了后面推导方便。</p>
<h4 id="构造拉格朗日函数"><a href="#构造拉格朗日函数" class="headerlink" title="构造拉格朗日函数"></a>构造拉格朗日函数</h4><p>我们总结一下经过转化后条件有两个：</p>
<script type="math/tex; mode=display">
\frac{1}{2}min\frac{1}{||w||^2}</script><script type="math/tex; mode=display">
y_i(w^Tx_i+b)\ge1</script><p>构造拉格朗日函数</p>
<script type="math/tex; mode=display">
L(w,b,\alpha)=\frac{1}{2}*\frac{1}{||w||}-\sum_{1}^{n}\alpha_i*(y_i*(w^T*x_i+b)-1)</script><p>则原优化问题可以转化为</p>
<p>$\theta(w)=maxL(w,b,\alpha),\alpha_i&gt;0$</p>
<p>求偏导得到： </p>
<script type="math/tex; mode=display">
\pmb{w}=\sum_{i=1}^{n}\alpha_iy_i\pmb{x_i}</script><script type="math/tex; mode=display">
0=\sum_{i=1}^{n}\alpha_iy_i</script><p>代入有</p>
<script type="math/tex; mode=display">
max(\sum_{i=1}^{n}\alpha_i-\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_j\pmb{x_i^{T}x_j})</script><p>如何求解上述式子，运用KKT条件</p>
<script type="math/tex; mode=display">\left\{ \begin{array}{rcl} \alpha_i>0  & & {    }\\ y_i(w^T\pmb{x}+b)\ge0    &      & {}\\ \alpha_i(y_i(w^T\pmb{x}+b)-1) =0 {}\end{array}\right.</script><p>这是一个对偶问题（凸优化，对偶问题，具体理论太数学，目前水平有限就暂时不做自己推导了）</p>
<h3 id="SMO算法"><a href="#SMO算法" class="headerlink" title="SMO算法"></a>SMO算法</h3><p>整个SMO算法包括两部分，求解两个变量的二次规划问题和选择这两个变量的启发式方法。我觉得SMO算法难就难在对两个α变量的选择过程。</p>
<p>$\sum_{i=1}^{n}\alpha_iy_i=0$,如果取$\alpha_1和\alpha_2$,定下$\alpha_2$的值，利用KKT条件，我们可以得出$\alpha_1$的值</p>
<p>这是一个关于两个$\alpha$的二次规划问题（我不想手敲了。。。）</p>
<h2 id="论文资料"><a href="#论文资料" class="headerlink" title="论文资料"></a>论文资料</h2><p>《Sequential Minimal Optimization A Fast Algorithm for Training Support Vector Machines》</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>模仿sklearn库自带的smo函数实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVM</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, C=<span class="number">1</span>, toler=<span class="number">0.001</span>, maxIter=<span class="number">500</span>, kernel_option=<span class="params">(<span class="string">""</span>, <span class="number">0</span>)</span>)</span>:</span></span><br><span class="line">        self.C = C  <span class="comment"># 惩罚参数</span></span><br><span class="line">        self.toler = toler  <span class="comment"># 迭代的终止条件之一</span></span><br><span class="line">        self.b = <span class="number">0</span>  <span class="comment"># 阈值</span></span><br><span class="line">        self.max_iter = maxIter  <span class="comment"># 最大迭代次数</span></span><br><span class="line">        self.kernel_opt = kernel_option  <span class="comment"># 选用的核函数及其参数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SVM_training</span><span class="params">(self, dataSet, labels ,)</span>:</span></span><br><span class="line">        <span class="comment"># 1.输入数据集</span></span><br><span class="line">        <span class="comment"># train_x_m, train_y_m = np.mat(train_x), np.mat(train_y)dataSet, labels,</span></span><br><span class="line">        self.train_x = np.mat(dataSet)  <span class="comment"># 训练数据集</span></span><br><span class="line">        self.train_y = np.mat(labels)  <span class="comment"># 测试数据集</span></span><br><span class="line">        self.train_y = self.train_y.T <span class="keyword">if</span> np.shape(self.train_y)[<span class="number">0</span>] == <span class="number">1</span> <span class="keyword">else</span> self.train_y  <span class="comment"># 将其转化为列向量</span></span><br><span class="line">        self.n_samples = np.shape(dataSet)[<span class="number">0</span>]  <span class="comment"># 训练样本的个数</span></span><br><span class="line">        self.alphas = np.mat(np.zeros((self.n_samples, <span class="number">1</span>)))  <span class="comment"># 拉格朗日乘子（一个全0的列向量）</span></span><br><span class="line">        self.error_tmp = np.mat(np.zeros((self.n_samples, <span class="number">2</span>)))  <span class="comment"># 保存E的缓存</span></span><br><span class="line">        self.kernel_mat = self.calc_kernel(self.train_x, self.kernel_opt)  <span class="comment"># 核函数的输出</span></span><br><span class="line">        <span class="comment"># 2.开始训练</span></span><br><span class="line">        entireSet = <span class="literal">True</span></span><br><span class="line">        alpha_pairs_changed = <span class="number">0</span></span><br><span class="line">        iteration = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> iteration &lt; self.max_iter <span class="keyword">and</span> (alpha_pairs_changed &gt; <span class="number">0</span> <span class="keyword">or</span> entireSet):</span><br><span class="line">            print(<span class="string">"\t iteration: "</span>, iteration)</span><br><span class="line">            alpha_pairs_changed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> entireSet:  <span class="comment"># 对所有样本</span></span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> range(self.n_samples):</span><br><span class="line">                    alpha_pairs_changed += self.choose_and_update(x)</span><br><span class="line">                iteration += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 对非边界样本</span></span><br><span class="line">                bound_samples = []</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_samples):</span><br><span class="line">                    <span class="keyword">if</span> self.alphas[i, <span class="number">0</span>] &gt; <span class="number">0</span> <span class="keyword">and</span> self.alphas[i, <span class="number">0</span>] &lt; self.C:</span><br><span class="line">                        bound_samples.append(i)</span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> bound_samples:</span><br><span class="line">                    alpha_pairs_changed += self.choose_and_update(x)</span><br><span class="line">                iteration += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> entireSet:</span><br><span class="line">                entireSet = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">elif</span> alpha_pairs_changed == <span class="number">0</span>:</span><br><span class="line">                entireSet = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_error</span><span class="params">(self, alpha_index_k)</span>:</span></span><br><span class="line">        <span class="comment">#误差值的计算</span></span><br><span class="line">        predict_k = float(np.multiply(self.alphas, self.train_y).T * self.kernel_mat[:, alpha_index_k] + self.b)</span><br><span class="line">        error_k = predict_k - float(self.train_y[alpha_index_k])</span><br><span class="line">        <span class="keyword">return</span> error_k</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">select_second_sample_j</span><span class="params">(self, alpha_index_i, error_i)</span>:</span></span><br><span class="line">        <span class="comment">#选择第二个变量</span></span><br><span class="line">        <span class="comment"># :param alpha_index_i(float): 第一个变量alpha_i的index_i</span></span><br><span class="line">        <span class="comment"># :param error_i(float): E_i</span></span><br><span class="line">        <span class="comment"># :return:第二个变量alpha_j的index_j和误差值E_j</span></span><br><span class="line"></span><br><span class="line">        self.error_tmp[alpha_index_i] = [<span class="number">1</span>, error_i]  <span class="comment"># 用来标记已被优化</span></span><br><span class="line">        candidate_alpha_list = np.nonzero(self.error_tmp[:, <span class="number">0</span>].A)[<span class="number">0</span>]  <span class="comment"># 因为是列向量，列数[1]都为0，只需记录行数[0]</span></span><br><span class="line">        max_step, max_step, error_j = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(candidate_alpha_list) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> alpha_index_k <span class="keyword">in</span> candidate_alpha_list:</span><br><span class="line">                <span class="keyword">if</span> alpha_index_k == alpha_index_i:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                error_k = self.cal_error(alpha_index_k)</span><br><span class="line">                <span class="keyword">if</span> abs(error_k - error_i) &gt; max_step:</span><br><span class="line">                    max_step = abs(error_k - error_i)</span><br><span class="line">                    alpha_index_j, error_j = alpha_index_k, error_k</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 随机选择</span></span><br><span class="line">            alpha_index_j = alpha_index_i</span><br><span class="line">            <span class="keyword">while</span> alpha_index_j == alpha_index_i:</span><br><span class="line">                alpha_index_j = np.random.randint(<span class="number">0</span>, self.n_samples)</span><br><span class="line">            error_j = self.cal_error(alpha_index_j)</span><br><span class="line">        <span class="keyword">return</span> alpha_index_j, error_j</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_error_tmp</span><span class="params">(self, alpha_index_k)</span>:</span></span><br><span class="line">        <span class="comment"># 重新计算误差值，并对其标记为已被优化</span></span><br><span class="line">        <span class="comment"># :param alpha_index_k: 要计算的变量α</span></span><br><span class="line">        <span class="comment"># :return: index为k的alpha新的误差</span></span><br><span class="line">        error = self.cal_error(alpha_index_k)</span><br><span class="line">        self.error_tmp[alpha_index_k] = [<span class="number">1</span>, error]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">choose_and_update</span><span class="params">(self, alpha_index_i)</span>:</span></span><br><span class="line">        <span class="comment"># 判断和选择两个alpha</span></span><br><span class="line">        error_i = self.cal_error(alpha_index_i)  <span class="comment"># 计算第一个样本的E_i</span></span><br><span class="line">        <span class="keyword">if</span> (self.train_y[alpha_index_i] * error_i &lt; -self.toler) <span class="keyword">and</span> (self.alphas[alpha_index_i] &lt; self.C) \</span><br><span class="line">                <span class="keyword">or</span> (self.train_y[alpha_index_i] * error_i &gt; self.toler) <span class="keyword">and</span> (self.alphas[alpha_index_i] &gt; <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># 1.选择第二个变量</span></span><br><span class="line">            alpha_index_j, error_j = self.select_second_sample_j(alpha_index_i, error_i)</span><br><span class="line">            alpha_i_old = self.alphas[alpha_index_i].copy()</span><br><span class="line">            alpha_j_old = self.alphas[alpha_index_j].copy()</span><br><span class="line">            <span class="comment"># 2.计算上下界</span></span><br><span class="line">            <span class="keyword">if</span> self.train_y[alpha_index_i] != self.train_y[alpha_index_j]:</span><br><span class="line">                L = max(<span class="number">0</span>, self.alphas[alpha_index_j] - self.alphas[alpha_index_i])</span><br><span class="line">                H = min(self.C, self.C + self.alphas[alpha_index_j] - self.alphas[alpha_index_i])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                L = max(<span class="number">0</span>, self.alphas[alpha_index_j] + self.alphas[alpha_index_i] - self.C)</span><br><span class="line">                H = min(self.C, self.alphas[alpha_index_j] + self.alphas[alpha_index_i])</span><br><span class="line">            <span class="keyword">if</span> L == H:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="comment"># 3.计算eta</span></span><br><span class="line">            eta = self.kernel_mat[alpha_index_i, alpha_index_i] + self.kernel_mat[alpha_index_j, alpha_index_j] - <span class="number">2.0</span> * \</span><br><span class="line">                  self.kernel_mat[alpha_index_i, alpha_index_j]</span><br><span class="line">            <span class="keyword">if</span> eta &lt;= <span class="number">0</span>:  <span class="comment"># 因为这个eta&gt;=0</span></span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="comment"># 4.更新alpha_j</span></span><br><span class="line">            self.alphas[alpha_index_j] += self.train_y[alpha_index_j] * (error_i - error_j) / eta</span><br><span class="line">            <span class="comment"># 5.根据范围确实最终的j</span></span><br><span class="line">            <span class="keyword">if</span> self.alphas[alpha_index_j] &gt; H:</span><br><span class="line">                self.alphas[alpha_index_j] = H</span><br><span class="line">            <span class="keyword">if</span> self.alphas[alpha_index_j] &lt; L:</span><br><span class="line">                self.alphas[alpha_index_j] = L</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 6.判断是否结束</span></span><br><span class="line">            <span class="keyword">if</span> abs(alpha_j_old - self.alphas[alpha_index_j]) &lt; <span class="number">0.00001</span>:</span><br><span class="line">                self.update_error_tmp(alpha_index_j)</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="comment"># 7.更新alpha_i</span></span><br><span class="line">            self.alphas[alpha_index_i] += self.train_y[alpha_index_i] * self.train_y[alpha_index_j] * (</span><br><span class="line">                        alpha_j_old - self.alphas[alpha_index_j])</span><br><span class="line">            <span class="comment"># 8.更新b</span></span><br><span class="line">            b1 = self.b - error_i - self.train_y[alpha_index_i] * self.kernel_mat[alpha_index_i, alpha_index_i] * (</span><br><span class="line">                        self.alphas[alpha_index_i] - alpha_i_old) \</span><br><span class="line">                 - self.train_y[alpha_index_j] * self.kernel_mat[alpha_index_i, alpha_index_j] * (</span><br><span class="line">                             self.alphas[alpha_index_j] - alpha_j_old)</span><br><span class="line">            b2 = self.b - error_j - self.train_y[alpha_index_i] * self.kernel_mat[alpha_index_i, alpha_index_j] * (</span><br><span class="line">                        self.alphas[alpha_index_i] - alpha_i_old) \</span><br><span class="line">                 - self.train_y[alpha_index_j] * self.kernel_mat[alpha_index_j, alpha_index_j] * (</span><br><span class="line">                             self.alphas[alpha_index_j] - alpha_j_old)</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; self.alphas[alpha_index_i] <span class="keyword">and</span> self.alphas[alpha_index_i] &lt; self.C:</span><br><span class="line">                self.b = b1</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">0</span> &lt; self.alphas[alpha_index_j] <span class="keyword">and</span> self.alphas[alpha_index_j] &lt; self.C:</span><br><span class="line">                self.b = b2</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.b = (b1 + b2) / <span class="number">2.0</span></span><br><span class="line">            <span class="comment"># 9.更新error</span></span><br><span class="line">            self.update_error_tmp(alpha_index_j)</span><br><span class="line">            self.update_error_tmp(alpha_index_i)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">svm_predict</span><span class="params">(self, test_data_x)</span>:</span></span><br><span class="line">        <span class="comment">#return预测值</span></span><br><span class="line">        kernel_value = self.calc_kernel_value(self.train_x, test_data_x, self.kernel_opt)</span><br><span class="line">        alp = self.alphas</span><br><span class="line">        predict = np.multiply(self.train_y, self.alphas).T * kernel_value + self.b</span><br><span class="line">        <span class="keyword">return</span> predict</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_prediction</span><span class="params">(self, test_data)</span>:</span></span><br><span class="line">        <span class="comment"># 对样本进行预测（预测多个数据）</span></span><br><span class="line">        <span class="comment"># input:  test_data(mat):测试数据</span></span><br><span class="line">        <span class="comment"># output: prediction(list):预测所属的类别</span></span><br><span class="line">        m = np.shape(test_data)[<span class="number">0</span>]</span><br><span class="line">        prediction = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            predict = self.svm_predict(test_data[i, :])</span><br><span class="line">            prediction.append(str(np.sign(predict)[<span class="number">0</span>, <span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_accuracy</span><span class="params">(self, test_x, test_y)</span>:</span></span><br><span class="line">        <span class="comment"># 计算准确率</span></span><br><span class="line">        n_samples = np.shape(test_x)[<span class="number">0</span>]</span><br><span class="line">        correct = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_samples):</span><br><span class="line">            predict = self.svm_predict(test_x[i, :])</span><br><span class="line">            <span class="keyword">if</span> np.sign(predict) == np.sign(test_y[i]):</span><br><span class="line">                correct += <span class="number">1</span></span><br><span class="line">        accuracy = correct / n_samples</span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_train_accracy</span><span class="params">(self)</span>:</span></span><br><span class="line">        accuracy = self.cal_accuracy(self.train_x, self.train_y)</span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_kernel</span><span class="params">(self, train_x, kernel_option)</span>:</span></span><br><span class="line">        <span class="comment"># 计算核函数的矩阵</span></span><br><span class="line">        <span class="comment"># :param train_x(matrix): 训练样本的特征值</span></span><br><span class="line">        <span class="comment"># :param kernel_option(tuple):  核函数的类型以及参数</span></span><br><span class="line">        <span class="comment"># :return: kernel_matrix(matrix):  样本的核函数的值</span></span><br><span class="line">        m = np.shape(train_x)[<span class="number">0</span>]</span><br><span class="line">        kernel_matrix = np.mat(np.zeros((m, m)))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            kernel_matrix[:, i] = self.calc_kernel_value(train_x, train_x[i, :], kernel_option)</span><br><span class="line">        <span class="keyword">return</span> kernel_matrix</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_kernel_value</span><span class="params">(self, train_x, train_x_i, kernel_option)</span>:</span></span><br><span class="line">        <span class="comment"># 样本之间的核函数值</span></span><br><span class="line">        <span class="comment"># :param train_x(matrix): 训练样本</span></span><br><span class="line">        <span class="comment"># :param train_x_i(matrix):   第i个训练样本 一个行向量</span></span><br><span class="line">        <span class="comment"># :param kernel_option(tuple):   核函数的类型以及参数</span></span><br><span class="line">        <span class="comment"># :return: kernel_value(matrix):  样本之间的核函数值</span></span><br><span class="line">        kernel_type = kernel_option[<span class="number">0</span>]</span><br><span class="line">        m = np.shape(train_x)[<span class="number">0</span>]</span><br><span class="line">        kernel_value = np.mat(np.zeros((m, <span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">if</span> kernel_type == <span class="string">"rbf"</span>:  <span class="comment"># 高斯核函数</span></span><br><span class="line">            sigma = kernel_option[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> sigma == <span class="number">0</span>:</span><br><span class="line">                sigma = <span class="number">1.0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">                diff = train_x[i, :] - train_x_i</span><br><span class="line">                kernel_value[i] = np.exp(diff * diff.T / (<span class="number">-2.0</span> * sigma ** <span class="number">2</span>))  <span class="comment"># 分子为差的2范数的平方</span></span><br><span class="line">        <span class="keyword">elif</span> kernel_type == <span class="string">"polynomial"</span>:</span><br><span class="line">            p = kernel_option[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">                kernel_value[i] = (train_x[i, :] * train_x_i.T + <span class="number">1</span>) ** p</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            kernel_value = train_x * train_x_i.T  <span class="comment"># 直接一个m*m矩阵×一个m*1的矩阵</span></span><br><span class="line">        <span class="keyword">return</span> kernel_value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_prediction</span><span class="params">(self, result_file, prediction)</span>:</span></span><br><span class="line">        <span class="comment"># 保存预测的结果</span></span><br><span class="line">        <span class="comment"># input:  result_file(string):结果保存的文件</span></span><br><span class="line">        <span class="comment">#         prediction(list):预测的结果</span></span><br><span class="line">        f = open(result_file, <span class="string">'w'</span>)</span><br><span class="line">        f.write(<span class="string">" "</span>.join(prediction))</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(data_file)</span>:</span></span><br><span class="line">    data_set, labels = [], []</span><br><span class="line">    <span class="keyword">with</span> open(data_file, <span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        textlist = f.readlines()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> textlist:</span><br><span class="line">            tmp = []</span><br><span class="line">            line = line.strip().split(<span class="string">" "</span>)</span><br><span class="line">            line_0=[]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> line[<span class="number">0</span>].split(<span class="string">','</span>):</span><br><span class="line">                line_0.append(float(i))</span><br><span class="line">            labels.append(line_0[<span class="number">8</span>])</span><br><span class="line">            i = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> line_0[<span class="number">0</span>:<span class="number">8</span>]:</span><br><span class="line"></span><br><span class="line">                tmp.append(word)</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            data_set.append(tmp)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (np.mat(data_set), np.mat(labels).T)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    filepath=<span class="string">'D:\\Python code\\machine learning\\pima-indians-diabetes.csv'</span></span><br><span class="line">    train_x, train_y = load_data(filepath)</span><br><span class="line">    <span class="comment"># print(train_y,train_x)</span></span><br><span class="line">    svm = SVM(C=<span class="number">0.6</span>, kernel_option=(<span class="string">"rbf"</span>, <span class="number">0.43</span>))</span><br><span class="line">    svm = svm.SVM_training(train_x, train_y,)</span><br><span class="line">    <span class="comment"># print(svm.alphas,svm.b)</span></span><br><span class="line">    accuracy = svm.get_train_accracy()</span><br><span class="line">    print(<span class="string">"The training accuracy is: %.3f%%"</span> % (accuracy * <span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p>样例<br><img src="https://raw.githubusercontent.com/Xinzhuo777/picgo/master/imagesvm%20.png"></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/07/20/PCA/" rel="prev" title="PCA算法原理及实现">
      <i class="fa fa-chevron-left"></i> PCA算法原理及实现
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/09/08/%E8%BF%90%E7%94%A8graphviz%E5%AF%B9%E5%86%B3%E7%AD%96%E6%A0%91%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="next" title="[graphviz]">
      [graphviz] <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM算法原理-一"><span class="nav-number">1.</span> <span class="nav-text">SVM算法原理(一)</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#间隔"><span class="nav-number">1.0.0.0.0.1.</span> <span class="nav-text">间隔</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SVM形式"><span class="nav-number">1.0.0.0.1.</span> <span class="nav-text">SVM形式</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#构造拉格朗日函数"><span class="nav-number">1.0.0.1.</span> <span class="nav-text">构造拉格朗日函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SMO算法"><span class="nav-number">1.0.1.</span> <span class="nav-text">SMO算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论文资料"><span class="nav-number">1.1.</span> <span class="nav-text">论文资料</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码实现"><span class="nav-number">1.2.</span> <span class="nav-text">代码实现</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Xinzhuo Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xinzhuo Li</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
